{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AIPI 590 - XAI | Assignment #2\n",
    "### Adversarial Patch Creation\n",
    "#### Developed by Tal Erez\n",
    "#### Colab Notebook:\n",
    "[![Open In Collab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/notthattal/AdversarialAI_Patch/blob/main/adversarial_patch.ipynb#scrollTo=jv7U4G4FodQf)\n",
    "\n",
    "### Introduction\n",
    "\n",
    "This notebook uses a small version of the ImageNet library to train an adversarial patch to fool the AI into thinking all images are the same animal.\n",
    "\n",
    "To increase robustness, random rotation and random scaling can be introduced by modifying the rotate and scale variables in the patch_attack() function. I chose to focus on one target class to keep consistency amongst different training attempts. A discussion of some of the results of these modifiers is present at the end of the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Install the required dependencies and import the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision adversarial-robustness-toolbox matplotlib pytorch-lightning ipywidgets tabulate\n",
    "\n",
    "#from google.colab import userdata\n",
    "from google.colab import userdata\n",
    "from IPython.display import display, HTML\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import pytorch_lightning as pl\n",
    "import tabulate\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "import torchvision.models as models\n",
    "import torch.utils.data as data\n",
    "from tqdm.notebook import tqdm\n",
    "import urllib.request\n",
    "from urllib.error import HTTPError\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Connect the Github repository to the Google Colab Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Remove Colab default sample_data if it exists\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./sample_data\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m      3\u001b[0m     get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrm -r ./sample_data\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Clone GitHub files to colab workspace\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# Remove Colab default sample_data if it exists\n",
    "if os.path.exists(\"./sample_data\"):\n",
    "    !rm -r ./sample_data\n",
    "\n",
    "# Clone GitHub files to colab workspace\n",
    "repo_name = \"AdversarialAI_Patch\"\n",
    "\n",
    "# Check if the repo already exists\n",
    "if not os.path.exists(\"/content/\" + repo_name):\n",
    "    git_path = 'https://github.com/notthattal/AdversarialAI_Patch.git'\n",
    "    !git clone \"{git_path}\"\n",
    "else:\n",
    "    print(f\"{repo_name} already exists.\")\n",
    "\n",
    "# Change working directory to location of notebook\n",
    "path_to_notebook = os.path.join(\"/content/\" + repo_name)\n",
    "%cd \"{path_to_notebook}\"\n",
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Set the Seed, ensure operations are deterministic on the GPU and set the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the seed\n",
    "pl.seed_everything(42)\n",
    "\n",
    "device = None\n",
    "\n",
    "# Fetching the device that will be used throughout this notebook\n",
    "if torch.backends.mps.is_available():\n",
    "    # Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "\n",
    "    #set device to use mps    \n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    # Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "    #set device to use cuda  \n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    #set device to use the cpu  \n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Using device\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Github URL where the dataset is stored for this tutorial\n",
    "base_url = \"https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial10/\"\n",
    "\n",
    "# Create paths if they don't exist yet\n",
    "os.makedirs(userdata.get('DATASET_PATH'), exist_ok=True)\n",
    "os.makedirs(userdata.get('CHECKPOINT_PATH'), exist_ok=True)\n",
    "os.makedirs(userdata.get('IMAGE_PATH'), exist_ok=True)\n",
    "\n",
    "# For each file, check whether it already exists. If not, try downloading it.\n",
    "file_name = \"TinyImageNet.zip\"\n",
    "file_path = os.path.join(userdata.get('DATASET_PATH'), file_name)\n",
    "if not os.path.isfile(file_path):\n",
    "    file_url = base_url + file_name\n",
    "    print(f\"Downloading {file_url}...\")\n",
    "    try:\n",
    "        urllib.request.urlretrieve(file_url, file_path)\n",
    "    except HTTPError as e:\n",
    "        print(\"Something went wrong. Please try to download the file from the GDrive folder, or contact the author with the full output including the following error:\\n\", e)\n",
    "    if file_name.endswith(\".zip\"):\n",
    "        print(\"Unzipping file...\")\n",
    "        with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(file_path.rsplit(\"/\",1)[0])\n",
    "            print(\"Unzip complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Load the ImageNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained ResNet-34 model with ImageNet weights\n",
    "pretrained_model = models.resnet34(weights='IMAGENET1K_V1')\n",
    "pretrained_model = pretrained_model.to(device)\n",
    "\n",
    "# Set model to evaluation mode\n",
    "pretrained_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Load the Dataset and Label Names\n",
    "  - set the transform\n",
    "  - load the dataset using the created transform and create the data loader\n",
    "  - load the label names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the Mean and Std from ImageNet\n",
    "NORM_MEAN = np.array([0.485, 0.456, 0.406])\n",
    "NORM_STD = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "# Convert the input image to PyTorch Tensor and normalize the images using the mean and standard deviation above\n",
    "plain_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=NORM_MEAN,\n",
    "                         std=NORM_STD)\n",
    "])\n",
    "\n",
    "# Load dataset and create data loader\n",
    "imagenet_path = os.path.join(userdata.get('DATASET_PATH'), \"TinyImageNet/\")\n",
    "assert os.path.isdir(imagenet_path), f\"Could not find the ImageNet dataset at expected path \\\"{imagenet_path}\\\". \" + \\\n",
    "                                     f\"Please make sure to have downloaded the ImageNet dataset here, or change the {userdata.get('DATASET_PATH')=} variable.\"\n",
    "dataset = torchvision.datasets.ImageFolder(root=imagenet_path, transform=plain_transforms)\n",
    "data_loader = data.DataLoader(dataset, batch_size=32, shuffle=False, drop_last=False, num_workers=8)\n",
    "\n",
    "# Load label names to interpret the label numbers 0 to 999\n",
    "with open(os.path.join(imagenet_path, \"label_list.json\"), \"r\") as f:\n",
    "    label_names = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Map patch values to ImageNet min and max\n",
    "  - Convert the NORM_MEAN and NORM_STD to PyTorch tensors\n",
    "  - Create a function \"patch_forward\" which converts the patch values from [-∞,∞] to ImageNet's [min, max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "TENSOR_MEANS, TENSOR_STD = torch.FloatTensor(NORM_MEAN)[:,None,None], torch.FloatTensor(NORM_STD)[:,None,None]\n",
    "def patch_forward(patch):\n",
    "    # Map patch values from [-infty,infty] to ImageNet min and max\n",
    "    patch = (torch.tanh(patch) + 1 - 2 * TENSOR_MEANS) / (2 * TENSOR_STD)\n",
    "    return patch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Create function which modifies the image for training\n",
    "  - Places the patch in a random location in the image\n",
    "  - If training the patch, will apply a random rotation for robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def place_patch(img, patch, training=False, rotate=0, scale=1):\n",
    "    for i in range(img.shape[0]):\n",
    "        \n",
    "        # Apply random rotation to the patch if training\n",
    "        final_patch = patch\n",
    "        if training:\n",
    "            #angle = np.random.uniform(0, 360)\n",
    "            final_patch = TF.rotate(patch, rotate)\n",
    "            \n",
    "            new_size = [int(final_patch.shape[1] * scale), int(final_patch.shape[2] * scale)]\n",
    "            final_patch = TF.resize(final_patch, new_size)\n",
    "\n",
    "        # Apply random placement of the patch regardless of training or testing\n",
    "        h_offset = np.random.randint(0,img.shape[2]-final_patch.shape[1]-1)\n",
    "        w_offset = np.random.randint(0,img.shape[3]-final_patch.shape[2]-1)\n",
    "\n",
    "        # Set the new transformation of the patch \n",
    "        img[i,:,h_offset:h_offset+final_patch.shape[1],w_offset:w_offset+final_patch.shape[2]] = patch_forward(final_patch)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Create function to evaluate the model\n",
    "  - Create a function that validates the effectiveness of the patch in fooling the model into predicting the target class\n",
    "  - The function excludes images in the target class\n",
    "  - Averages performance among 4 random placements and returns the accuracy metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_patch(model, patch, val_loader, target_class):\n",
    "    model.eval()\n",
    "    tp, tp_5, counter = 0., 0., 0.\n",
    "    with torch.no_grad():\n",
    "        for img, img_labels in tqdm(val_loader, desc=\"Validating...\", leave=False):\n",
    "            # For stability, place the patch at 4 random locations per image, and average the performance\n",
    "            for _ in range(4): \n",
    "                patch_img = place_patch(img, patch)\n",
    "                patch_img = patch_img.to(device)\n",
    "                img_labels = img_labels.to(device)\n",
    "                pred = model(patch_img)\n",
    "                # In the accuracy calculation, we need to exclude the images that are of our target class\n",
    "                # as we would not \"fool\" the model into predicting those\n",
    "                tp += torch.logical_and(pred.argmax(dim=-1) == target_class, img_labels != target_class).sum()\n",
    "                tp_5 += torch.logical_and((pred.topk(5, dim=-1)[1] == target_class).any(dim=-1), img_labels != target_class).sum()\n",
    "                counter += (img_labels != target_class).sum()\n",
    "    acc = tp/counter\n",
    "    top5 = tp_5/counter\n",
    "    return acc, top5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10: Attack the Image\n",
    "  - Creates a function \"patch_attack\" which is used to train a model to create a patch that fools a model into predicting a specific target class\n",
    "  - Trains it over a specified number of epochs and evaluates the patch effectiveness on a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_attack(model, target_class, patch_size=64, num_epochs=5):\n",
    "    # Leave a small set of images out to check generalization\n",
    "    # In most of our experiments, the performance on the hold-out data points\n",
    "    # was as good as on the training set. Overfitting was little possible due\n",
    "    # to the small size of the patches.\n",
    "    train_set, val_set = torch.utils.data.random_split(dataset, [4500, 500])\n",
    "    train_loader = data.DataLoader(train_set, batch_size=32, shuffle=True, drop_last=True, num_workers=8)\n",
    "    val_loader = data.DataLoader(val_set, batch_size=32, shuffle=False, drop_last=False, num_workers=4)\n",
    "    \n",
    "    # Create parameter and optimizer\n",
    "    if not isinstance(patch_size, tuple):\n",
    "        patch_size = (patch_size, patch_size)\n",
    "    patch = nn.Parameter(torch.zeros(3, patch_size[0], patch_size[1]), requires_grad=True)\n",
    "    optimizer = torch.optim.SGD([patch], lr=1e-1, momentum=0.8)\n",
    "    loss_module = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        t = tqdm(train_loader, leave=False)\n",
    "        scale = np.random.uniform(1, 1)\n",
    "        for img, _ in t:\n",
    "            rotate = np.random.uniform(0, 360)\n",
    "            img = place_patch(img, patch, True, rotate, scale)\n",
    "            img = img.to(device).to(next(model.parameters()).dtype)\n",
    "            pred = model(img)\n",
    "            labels = torch.zeros(img.shape[0], device=pred.device, dtype=torch.long).fill_(target_class)\n",
    "            loss = loss_module(pred, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.mean().backward()\n",
    "            optimizer.step()\n",
    "            t.set_description(f\"Epoch {epoch}, Loss: {loss.item():4.2f}\")\n",
    "    \n",
    "    # Final validation\n",
    "    acc, top5 = eval_patch(model, patch, val_loader, target_class)\n",
    "    \n",
    "    return patch.data, {\"acc\": acc.item(), \"top5\": top5.item()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 11: Get the patch/patches\n",
    "  - Main training function for the model\n",
    "  - for each target class we want to generate a patch for, and for each patch size we want to generate, we train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patches(class_names, patch_sizes, num_epochs=5):\n",
    "    result_dict = dict()\n",
    "\n",
    "    # Loop over all classes and patch sizes\n",
    "    for name in class_names:\n",
    "        result_dict[name] = dict()\n",
    "        for patch_size in patch_sizes:\n",
    "            c = label_names.index(name)\n",
    "            file_name = os.path.join(userdata.get('CHECKPOINT_PATH'), f\"{name}_{patch_size}_patch.pt\")\n",
    "\n",
    "            # Delete patch if pretrained file exists\n",
    "            if os.path.isfile(file_name):\n",
    "                os.remove(file_name)\n",
    "\n",
    "            # Start training\n",
    "            patch, val_results = patch_attack(pretrained_model, target_class=c, patch_size=patch_size, num_epochs=num_epochs)\n",
    "            print(f\"Validation results for {name} and {patch_size}:\", val_results)\n",
    "            torch.save(patch, file_name)\n",
    "\n",
    "            # Load evaluation results if exist, otherwise manually evaluate the patch\n",
    "            results = eval_patch(pretrained_model, patch, data_loader, target_class=c)\n",
    "\n",
    "            # Store results and the patches in a dict for better access\n",
    "            result_dict[name][patch_size] = {\n",
    "                \"results\": results,\n",
    "                \"patch\": patch\n",
    "            }\n",
    "\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 12: Start Training\n",
    "  - Set the target classes for which to create patches\n",
    "  - Set the patch sizes to be trained\n",
    "  - Start the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"bulbul\"]\n",
    "patch_sizes = [64]\n",
    "\n",
    "patch_dict = get_patches(class_names, patch_sizes, num_epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 13: Display the patch/patches\n",
    "  - Create a plot for every patch created\n",
    "  - Display each plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_patches(class_name, patch_size):\n",
    "    fig, ax = plt.subplots(figsize=(2.2, 2.2))\n",
    "    patch = patch_dict[class_name][patch_size][\"patch\"]\n",
    "    patch = (torch.tanh(patch) + 1) / 2 # Parameter to pixel values\n",
    "    patch = patch.cpu().permute(1, 2, 0).numpy()\n",
    "    patch = np.clip(patch, a_min=0.0, a_max=1.0)\n",
    "\n",
    "    # Save the patch in the specified directory\n",
    "    save_path = os.path.join(userdata.get('IMAGE_PATH'), f\"patch_{class_name}_{patch_size}.jpg\")\n",
    "    plt.imsave(save_path, patch)\n",
    "\n",
    "    ax.imshow(patch)\n",
    "    ax.set_title(f\"{class_name}, size {patch_size}\")\n",
    "    ax.axis('off')\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "    plt.show()\n",
    "\n",
    "for size in patch_sizes:\n",
    "    for name in class_names:\n",
    "        show_patches(name, size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 14: Create HTML code to set the font size for the following table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<!-- Some HTML code to increase font size in the following table -->\n",
    "<style>\n",
    "th {font-size: 120%;}\n",
    "td {font-size: 120%;}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 15: Display Patch Attack Performance\n",
    "  - Set the font size for the table\n",
    "  - Generate a table showing patch_attack performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_table(top_1=True):\n",
    "    i = 0 if top_1 else 1\n",
    "    table = [[name] + [f\"{(100.0 * patch_dict[name][psize]['results'][i]):4.2f}%\" for psize in patch_sizes]\n",
    "             for name in class_names]\n",
    "    display(HTML(tabulate.tabulate(table, tablefmt='html', headers=[\"Class name\"] + [f\"Patch size {psize}x{psize}\" for psize in patch_sizes])))\n",
    "\n",
    "show_table(top_1=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 17: Visualize the predictions\n",
    "  - Create a plot for a specified number of images\n",
    "  - display the image with the embedded patch\n",
    "  - show a bar graph with the model's top predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_prediction(img, label, pred, index, K=5, adv_img=None, noise=None):\n",
    "    \n",
    "    if isinstance(img, torch.Tensor):\n",
    "        # Tensor image to numpy\n",
    "        img = img.cpu().permute(1, 2, 0).numpy()\n",
    "        img = (img * NORM_STD[None,None]) + NORM_MEAN[None,None]\n",
    "        img = np.clip(img, a_min=0.0, a_max=1.0)\n",
    "        label = label.item()\n",
    "    \n",
    "    # Plot on the left the image with the true label as title.\n",
    "    # On the right, have a horizontal bar plot with the top k predictions including probabilities\n",
    "    if noise is None or adv_img is None:\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(10,2), gridspec_kw={'width_ratios': [1, 1]})\n",
    "    else:\n",
    "        fig, ax = plt.subplots(1, 5, figsize=(12,2), gridspec_kw={'width_ratios': [1, 1, 1, 1, 2]})\n",
    "\n",
    "    save_path = CHECKPOINT_PATH + \"/images/\" + str(index) + \".jpg\"\n",
    "    if save_path is not None:\n",
    "        img_pil = Image.fromarray((img * 255).astype(np.uint8))  # Convert from [0,1] to [0,255] and uint8\n",
    "        img_pil.save(save_path, format='JPEG')\n",
    "    \n",
    "    ax[0].imshow(img)\n",
    "    ax[0].set_title(label_names[label])\n",
    "    ax[0].axis('off')\n",
    "    \n",
    "    if adv_img is not None and noise is not None:\n",
    "        # Visualize adversarial images\n",
    "        adv_img = adv_img.cpu().permute(1, 2, 0).numpy()\n",
    "        adv_img = (adv_img * NORM_STD[None,None]) + NORM_MEAN[None,None]\n",
    "        adv_img = np.clip(adv_img, a_min=0.0, a_max=1.0)\n",
    "        ax[1].imshow(adv_img)\n",
    "        ax[1].set_title('Adversarial')\n",
    "        ax[1].axis('off')\n",
    "        # Visualize noise\n",
    "        noise = noise.cpu().permute(1, 2, 0).numpy()\n",
    "        noise = noise * 0.5 + 0.5 # Scale between 0 to 1 \n",
    "        ax[2].imshow(noise)\n",
    "        ax[2].set_title('Noise')\n",
    "        ax[2].axis('off')\n",
    "        # buffer\n",
    "        ax[3].axis('off')\n",
    "    \n",
    "    if abs(pred.sum().item() - 1.0) > 1e-4:\n",
    "        pred = torch.softmax(pred, dim=-1)\n",
    "    topk_vals, topk_idx = pred.topk(K, dim=-1)\n",
    "    topk_vals, topk_idx = topk_vals.cpu().numpy(), topk_idx.cpu().numpy()\n",
    "    ax[-1].barh(np.arange(K), topk_vals*100.0, align='center', color=[\"C0\" if topk_idx[i]!=label else \"C2\" for i in range(K)])\n",
    "    ax[-1].set_yticks(np.arange(K))\n",
    "    ax[-1].set_yticklabels([label_names[c] for c in topk_idx])\n",
    "    ax[-1].invert_yaxis()\n",
    "    ax[-1].set_xlabel('Confidence')\n",
    "    ax[-1].set_title('Predictions')\n",
    "    \n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 18: Retrieve input data and labels from data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "exmp_batch, label_batch = next(iter(data_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 19: Predict and display predictions for a specified number of examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_patch_attack(patch):\n",
    "    patch_batch = exmp_batch.clone()\n",
    "    patch_batch = place_patch(patch_batch, patch)\n",
    "    with torch.no_grad():\n",
    "        patch_preds = pretrained_model(patch_batch.to(device))\n",
    "    for i in range(1,10):\n",
    "        show_prediction(patch_batch[i], label_batch[i], patch_preds[i], i)\n",
    "\n",
    "perform_patch_attack(patch_dict['bulbul'][64]['patch'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "In order to determine which patch was the most effective, and to try to improve the robustness and accuracy to which the created patch was successful I modified the learning algorithm in multiple ways to test efficiency.\n",
    "\n",
    "For testing purposes, I attempted to create a patch using SGD and the Adam optimizer. The Adam optimizer consistently resulted in lower accuracy, so I determined that I should stick with using the SGD optimizer. \n",
    "\n",
    "Once the optimizer was decided upon, I attempted to modify the learning rate in a few different ways. First was just decreasing the learning rate from 1e-1 to 1e-2 and the second was to try and use learning rate scheduling. But, ultimately 1e-1 proved to result in the highest accuracy. Similarly, modifying the momentum, introducing weight decays and modifying the loss function all resulted in lower accuracy than the base model set in the tutorial.\n",
    "\n",
    "To increase robustness, I introduced a random rotation and random scaling. For each, the base model, rotation without scaling and rotation with scaling I have generated patches are presented below along with their overall accuracy % as reported by the eval_patch() function.\n",
    "\n",
    "#### Base (No Rotation or Scaling):\n",
    "\n",
    "5 epochs: 99.92% <br> <br>\n",
    "![](./premade_patches/patch_base_5.jpg)\n",
    "\n",
    "10 epochs: 99.98% accuracy <br> <br>\n",
    "![](./premade_patches/patch_base_10.jpg)\n",
    "\n",
    "#### Rotation No Scaling:\n",
    "*Note: Rotations were in the range of 0 to 360 degrees.\n",
    "\n",
    "10 epochs, but random rotation was only applied once per epoch: 87.89% accuracy <br> <br>\n",
    "![](./premade_patches/patch_rotate_epoch.jpg)\n",
    "\n",
    "10 epochs: 94.94% accuracy <br> <br>\n",
    "![](./premade_patches/patch_rotate_10.jpg)\n",
    "\n",
    "15 epochs: 97.42% accuracy <br> <br>\n",
    "![](./premade_patches/patch_rotate_15.jpg)\n",
    "\n",
    "#### Rotation And Scaling:\n",
    "*Note: Scaling was performed once per epoch unless specified. Patches were scaled randomly from 0.5 to 1 times the original size and were applied for both the x and y axes of the image uniformly to keep the patch square.\n",
    "\n",
    "10 epochs every step: 66.32% accuracy <br> <br>\n",
    "![](./premade_patches/patch_scaling_every_10.jpg)\n",
    "\n",
    "10 epochs: 73.65% accuracy <br> <br>\n",
    "![](./premade_patches/patch_scaling_10.jpg)\n",
    "\n",
    "25 epochs: 90.85% accuracy <br> <br>\n",
    "![](./premade_patches/patch_scaling_25.jpg)\n",
    "\n",
    "50 epochs: 95.95% accuracy <br> <br>\n",
    "![](./premade_patches/patch_scaling_50.jpg)\n",
    "\n",
    "Rotation and scaling was attempted due to the discussion in the tutorial referencing Brown et al. As we can see, the base model provided in the tutorial (with a slight bump to the number of epochs) resulted in the highest accuracy of prediction from the model. However, we see that with some modifications to the number of epochs and how we introduce scaling, we can still achieve a high level of accuracy with random scaling and rotations. Some surprising results were that although implementing scaling at every step lowered the accuracy, for rotation, applying it once per epoch instead of every step actually caused worse performance.\n",
    "\n",
    "### Combining Patches\n",
    "Along with testing multiple different types of patches, I also combined my patches to see if it was still able to fool the classifier. Here are the results:\n",
    "\n",
    "Combining both base cases <br>\n",
    "*Result: Correctly classified as Bulbul bird* <br> <br>\n",
    "![](./premade_patches/combo_base.jpg) <br>\n",
    "\n",
    "Combining all rotated images <br>\n",
    "*Result: The model failed and classified the image as a house finch* <br> <br>\n",
    "![](./premade_patches/combo_rotate.jpg) <br>\n",
    "\n",
    "Combining all scaled images <br>\n",
    "*Result: The model failed and classified the image as a barn spider* <br> <br>\n",
    "![](./premade_patches/combo_scale.jpg) <br>\n",
    "\n",
    "Combining all images which used 10 epochs (i.e. a base, rotated and a scaled image) <br>\n",
    "*Result: The model failed and classified the image as a pillow* <br> <br>\n",
    "![](./premade_patches/combo_10.jpg) <br>\n",
    "\n",
    "### Citations\n",
    "Lippe, Phillip, & Bent, Brinnae, PhD \"Tutorial 10: Adversarial attacks.\" Github, 2024, https://github.com/AIPI-590-XAI/Duke-AI-XAI/blob/main/adversarial-ai-example-notebooks/adversarial_attacks.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}